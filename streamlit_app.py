import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import datetime
from sklearn.preprocessing import MinMaxScaler

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="äº¤æ˜“ä¿¡æ¯æ±‡æ€»çœ‹æ¿",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2rem;
    }
</style>
""", unsafe_allow_html=True)

# æ•°æ®åŠ è½½å‡½æ•°
@st.cache_data
def load_data():
    """åŠ è½½å¹¶é¢„å¤„ç†æ•°æ®"""
    df = pd.read_excel('äº¤æ˜“ä¿¡æ¯æ±‡æ€».xlsx')
    df['äº¤æ˜“æ—¥æœŸ'] = pd.to_datetime(df['äº¤æ˜“æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
    df['è§‚å¯Ÿæ—¥'] = pd.to_datetime(df['è§‚å¯Ÿæ—¥'], errors='coerce')
    df['èµ·å§‹æ—¥æœŸ'] = pd.to_datetime(df['èµ·å§‹æ—¥æœŸ'], errors='coerce')
    df['åˆ°æœŸæ—¥'] = pd.to_datetime(df['åˆ°æœŸæ—¥'], errors='coerce')
    return df

def expand_observation_dates(df):
    """å±•å¼€é›ªçƒæ•²å‡ºè§‚å¯Ÿæ—¥åºåˆ—"""
    snowball_data = df[df['é›ªçƒæ•²å‡ºè§‚å¯Ÿæ—¥åºåˆ—'].notna()].copy()

    unique_trades = snowball_data.groupby('Trade Id').agg({
        'æ ‡çš„åç§°': 'first',
        'äº¤æ˜“æ—¥æœŸ': 'first',
        'èµ·å§‹æ—¥æœŸ': 'first',
        'åˆ°æœŸæ—¥': 'first',
        'TRADE_KEYWORD.æœŸæƒç‰¹æ®Šç±»å‹': 'first',
        'é›ªçƒæ•²å‡ºè§‚å¯Ÿæ—¥åºåˆ—': 'first'
    }).reset_index()

    expanded_data = []

    for idx, row in unique_trades.iterrows():
        trade_id = row['Trade Id']
        underlying = row['æ ‡çš„åç§°']
        option_type = row['TRADE_KEYWORD.æœŸæƒç‰¹æ®Šç±»å‹']
        start_date = row['èµ·å§‹æ—¥æœŸ']
        maturity = row['åˆ°æœŸæ—¥']

        obs_dates_str = str(row['é›ªçƒæ•²å‡ºè§‚å¯Ÿæ—¥åºåˆ—']).split(';')

        for i, date_str in enumerate(obs_dates_str, 1):
            date_obj = datetime.datetime.strptime(date_str.strip(), '%Y%m%d')

            expanded_data.append({
                'Trade Id': trade_id,
                'æ ‡çš„åç§°': underlying,
                'æœŸæƒç±»å‹': option_type,
                'èµ·å§‹æ—¥æœŸ': start_date,
                'åˆ°æœŸæ—¥': maturity,
                'è§‚å¯Ÿæ—¥åºå·': i,
                'è§‚å¯Ÿæ—¥': date_obj,
                'è§‚å¯Ÿæ—¥æœŸ': date_obj.strftime('%Y-%m-%d'),
                'æ˜ŸæœŸ': date_obj.strftime('%A'),
                'æ€»è§‚å¯Ÿæ—¥æ•°': len(obs_dates_str)
            })

    obs_df = pd.DataFrame(expanded_data)
    return obs_df

def create_enhanced_calendar_heatmap(obs_df):
    """åˆ›å»ºå¸¦Trade IDæ ‡æ³¨çš„æ—¥å†çƒ­åŠ›å›¾"""
    # æŒ‰æ—¥æœŸç»Ÿè®¡ï¼Œæ”¶é›†æ‰€æœ‰Trade ID
    daily_stats = obs_df.groupby('è§‚å¯Ÿæ—¥æœŸ').agg({
        'Trade Id': lambda x: list(x),
        'æ ‡çš„åç§°': lambda x: list(x),
        'è§‚å¯Ÿæ—¥åºå·': lambda x: list(x)
    }).reset_index()

    daily_stats['è§‚å¯Ÿæ¬¡æ•°'] = daily_stats['Trade Id'].apply(len)
    daily_stats['è§‚å¯Ÿæ—¥'] = pd.to_datetime(daily_stats['è§‚å¯Ÿæ—¥æœŸ'])

    # è·å–æ—¥æœŸèŒƒå›´
    min_date = obs_df['è§‚å¯Ÿæ—¥'].min()
    max_date = obs_df['è§‚å¯Ÿæ—¥'].max()

    # ç”Ÿæˆæ‰€æœ‰æ—¥æœŸ
    all_dates = pd.date_range(start=min_date, end=max_date, freq='D')

    # åˆ›å»ºå®Œæ•´çš„æ—¥æœŸæ•°æ®æ¡†
    full_df = pd.DataFrame({'è§‚å¯Ÿæ—¥': all_dates})
    full_df['æ—¥æœŸ'] = full_df['è§‚å¯Ÿæ—¥'].dt.strftime('%Y-%m-%d')
    full_df = full_df.merge(daily_stats[['è§‚å¯Ÿæ—¥æœŸ', 'è§‚å¯Ÿæ¬¡æ•°', 'Trade Id', 'æ ‡çš„åç§°', 'è§‚å¯Ÿæ—¥åºå·']],
                           left_on='æ—¥æœŸ', right_on='è§‚å¯Ÿæ—¥æœŸ', how='left')
    full_df['è§‚å¯Ÿæ¬¡æ•°'] = full_df['è§‚å¯Ÿæ¬¡æ•°'].fillna(0)

    # æ·»åŠ æ—¥å†ä¿¡æ¯
    full_df['å¹´'] = full_df['è§‚å¯Ÿæ—¥'].dt.year
    full_df['æœˆ'] = full_df['è§‚å¯Ÿæ—¥'].dt.month
    full_df['æ—¥'] = full_df['è§‚å¯Ÿæ—¥'].dt.day
    full_df['æ˜ŸæœŸ'] = full_df['è§‚å¯Ÿæ—¥'].dt.dayofweek
    full_df['æ˜ŸæœŸå'] = full_df['è§‚å¯Ÿæ—¥'].dt.strftime('%A')
    full_df['å¹´æœˆ'] = full_df['è§‚å¯Ÿæ—¥'].dt.strftime('%Y-%m')

    # è®¡ç®—å‘¨æ•°
    def get_week_of_month(date):
        first_day = date.replace(day=1)
        adjusted_dom = date.day + first_day.weekday()
        return int(np.ceil(adjusted_dom / 7.0)) - 1

    full_df['æœˆå†…å‘¨æ•°'] = full_df['è§‚å¯Ÿæ—¥'].apply(get_week_of_month)

    # åˆ›å»ºæ‚¬åœæ–‡æœ¬
    def create_hover_text(row):
        if row['è§‚å¯Ÿæ¬¡æ•°'] > 0:
            text = f"<b>ğŸ“… {row['æ—¥æœŸ']} ({row['æ˜ŸæœŸå']})</b><br>"
            text += f"<b>è§‚å¯Ÿæ¬¡æ•°: {int(row['è§‚å¯Ÿæ¬¡æ•°'])}</b><br><br>"

            trades = row['Trade Id']
            underlyings = row['æ ‡çš„åç§°']
            sequences = row['è§‚å¯Ÿæ—¥åºå·']

            underlying_groups = {}
            for i, (trade, underlying, seq) in enumerate(zip(trades, underlyings, sequences)):
                if underlying not in underlying_groups:
                    underlying_groups[underlying] = []
                underlying_groups[underlying].append((trade, seq))

            for underlying, trade_list in sorted(underlying_groups.items()):
                text += f"<b>ğŸ“Š {underlying}</b><br>"
                for trade, seq in trade_list:
                    text += f"  â€¢ Trade {trade} (è§‚å¯Ÿ#{seq})<br>"
                text += "<br>"

            return text.rstrip('<br>')
        else:
            return f"{row['æ—¥æœŸ']}<br>æ— è§‚å¯Ÿ"

    full_df['hover_text'] = full_df.apply(create_hover_text, axis=1)

    # æŒ‰å¹´æœˆåˆ†ç»„åˆ›å»ºå­å›¾
    year_months = sorted(full_df['å¹´æœˆ'].unique())

    # è®¡ç®—è¡Œåˆ—æ•°
    n_months = len(year_months)
    cols = 3
    rows = int(np.ceil(n_months / cols))

    # åˆ›å»ºå­å›¾
    fig = make_subplots(
        rows=rows, cols=cols,
        subplot_titles=[f"<b>{ym}</b>" for ym in year_months],
        vertical_spacing=0.08,
        horizontal_spacing=0.05,
        specs=[[{'type': 'heatmap'} for _ in range(cols)] for _ in range(rows)]
    )

    weekday_labels = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']

    for idx, ym in enumerate(year_months):
        row = idx // cols + 1
        col = idx % cols + 1

        month_df = full_df[full_df['å¹´æœˆ'] == ym].copy()

        # åˆ›å»ºçƒ­åŠ›å›¾çŸ©é˜µ
        heatmap_matrix = np.full((6, 7), np.nan)
        hover_matrix = [['' for _ in range(7)] for _ in range(6)]
        text_matrix = [['' for _ in range(7)] for _ in range(6)]

        for _, row_data in month_df.iterrows():
            week = row_data['æœˆå†…å‘¨æ•°']
            day = row_data['æ˜ŸæœŸ']
            if week < 6:
                heatmap_matrix[week][day] = row_data['è§‚å¯Ÿæ¬¡æ•°']
                hover_matrix[week][day] = row_data['hover_text']

                day_num = row_data['æ—¥']
                obs_count = int(row_data['è§‚å¯Ÿæ¬¡æ•°'])
                if obs_count > 0:
                    if obs_count == 1:
                        text_matrix[week][day] = f"<b>{day_num}</b>"
                    else:
                        text_matrix[week][day] = f"<b>{day_num}</b><br>({obs_count})"
                else:
                    text_matrix[week][day] = str(day_num)

        # æ·»åŠ çƒ­åŠ›å›¾
        heatmap = go.Heatmap(
            z=heatmap_matrix,
            x=weekday_labels,
            y=list(range(6)),
            text=text_matrix,
            hovertext=hover_matrix,
            hoverinfo='text',
            texttemplate='%{text}',
            textfont={"size": 9},
            colorscale=[
                [0, '#F8F9FA'],
                [0.2, '#E3F2FD'],
                [0.4, '#90CAF9'],
                [0.6, '#42A5F5'],
                [0.8, '#1976D2'],
                [1.0, '#0D47A1']
            ],
            showscale=(idx == 0),
            colorbar=dict(
                title=dict(text="<b>è§‚å¯Ÿæ¬¡æ•°</b>"),
                tickmode="linear",
                tick0=0,
                dtick=1
            ) if idx == 0 else None,
            zmin=0,
            zmax=max(6, full_df['è§‚å¯Ÿæ¬¡æ•°'].max())
        )

        fig.add_trace(heatmap, row=row, col=col)

    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title={
            'text': 'é›ªçƒæ•²å‡ºè§‚å¯Ÿæ—¥æ—¥å†',
            'x': 0.5,
            'xanchor': 'center',
            'font': {'size': 18}
        },
        height=280 * rows,
        showlegend=False,
        paper_bgcolor='white',
        plot_bgcolor='white'
    )

    fig.update_yaxes(showticklabels=False)

    return fig

def print_trade_details(trade_id, df):
    """æ˜¾ç¤ºäº¤æ˜“è¯¦æƒ…"""
    trade_data = df.loc[df['Trade Id'] == trade_id]

    if trade_data.empty:
        st.error(f"æœªæ‰¾åˆ°äº¤æ˜“ ID: {trade_id}")
        return

    latest_record = trade_data.sort_values('è§‚å¯Ÿæ—¥').iloc[-1]

    st.markdown("### ğŸ“‹ äº¤æ˜“è¯¦æƒ…")

    # åŸºæœ¬ä¿¡æ¯
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("äº¤æ˜“æ—¥æœŸ", latest_record['äº¤æ˜“æ—¥æœŸ'])
        st.metric("äº¤æ˜“æ–¹å‘", latest_record['äº¤æ˜“æ–¹å‘'])
    with col2:
        st.metric("äº§å“ç±»å‹", latest_record['äº§å“ç±»å‹'])
        st.metric("æœŸæƒç±»å‹", latest_record['TRADE_KEYWORD.æœŸæƒç‰¹æ®Šç±»å‹'])
    with col3:
        st.metric("æ ‡çš„èµ„äº§", latest_record['æ ‡çš„åç§°'])
        st.metric("äº¤å‰²å¸ç§", latest_record['äº¤å‰²å¸ç§'])

    st.markdown("---")

    # æ—¶é—´ä¿¡æ¯
    col1, col2, col3 = st.columns(3)
    with col1:
        start_date = latest_record['èµ·å§‹æ—¥æœŸ']
        if pd.notna(start_date):
            st.metric("èµ·å§‹æ—¥æœŸ", start_date.strftime('%Y-%m-%d'))
        else:
            st.metric("èµ·å§‹æ—¥æœŸ", "N/A")
    with col2:
        maturity_date = latest_record['åˆ°æœŸæ—¥']
        if pd.notna(maturity_date):
            st.metric("åˆ°æœŸæ—¥æœŸ", maturity_date.strftime('%Y-%m-%d'))
        else:
            st.metric("åˆ°æœŸæ—¥æœŸ", "N/A")
    with col3:
        if pd.notna(latest_record['åˆ°æœŸæ—¥']):
            days_remaining = (latest_record['åˆ°æœŸæ—¥'] - datetime.datetime.now()).days
            st.metric("å‰©ä½™å¤©æ•°", f"{days_remaining} å¤©")
        else:
            st.metric("å‰©ä½™å¤©æ•°", "N/A")

    st.markdown("---")

    # å…³é”®å‚æ•°
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        strike = latest_record['è¡Œæƒä»·']
        st.metric("è¡Œæƒä»·", f"{strike:.2f}" if pd.notna(strike) else "N/A")
    with col2:
        barrier = latest_record['éšœç¢å‘ä¸Šæ•²å‡ºæ°´å¹³']
        st.metric("éšœç¢æ°´å¹³", f"{barrier:.2f}" if pd.notna(barrier) else "N/A")
    with col3:
        notional = latest_record['åä¹‰æœ¬é‡‘']
        st.metric("åä¹‰æœ¬é‡‘", f"{notional:,.0f}" if pd.notna(notional) else "N/A")
    with col4:
        vol = latest_record['æ³¢åŠ¨ç‡']
        st.metric("æ³¢åŠ¨ç‡", f"{vol:.4f}%" if pd.notna(vol) else "N/A")

    st.markdown("---")

    # è´¢åŠ¡æŒ‡æ ‡
    st.markdown("### ğŸ’° è´¢åŠ¡æŒ‡æ ‡")
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        premium = latest_record['æœŸæƒè´¹']
        st.metric("æœŸæƒè´¹", f"{premium:,.2f}" if pd.notna(premium) else "N/A")
    with col2:
        npv = latest_record['æœŸæƒä¼°å€¼ NPV']
        st.metric("æœŸæƒä¼°å€¼(NPV)", f"{npv:,.2f}" if pd.notna(npv) else "N/A")
    with col3:
        total_pnl = latest_record['æ€»ç›ˆäº']
        st.metric("æ€»ç›ˆäº", f"{total_pnl:,.2f}" if pd.notna(total_pnl) else "N/A")
    with col4:
        ytd_pnl = latest_record['æœ¬å¹´æ€»ç›ˆäº']
        st.metric("æœ¬å¹´ç›ˆäº", f"{ytd_pnl:,.2f}" if pd.notna(ytd_pnl) else "N/A")
    with col5:
        overnight_pnl = latest_record['éš”å¤œç›ˆäº']
        st.metric("éš”å¤œç›ˆäº", f"{overnight_pnl:,.2f}" if pd.notna(overnight_pnl) else "N/A")

    st.markdown("---")

    # å¸Œè…Šå€¼
    st.markdown("### ğŸ“Š å¸Œè…Šå€¼")
    col1, col2, col3, col4, col5 = st.columns(5)
    with col1:
        delta = latest_record['DELTA(æœŸæƒ)']
        st.metric("Delta", f"{delta:,.2f}" if pd.notna(delta) else "N/A")
    with col2:
        gamma = latest_record['GAMMA']
        st.metric("Gamma", f"{gamma:,.2f}" if pd.notna(gamma) else "N/A")
    with col3:
        vega = latest_record['VEGA']
        st.metric("Vega", f"{vega:,.2f}" if pd.notna(vega) else "N/A")
    with col4:
        rho = latest_record['RHO']
        st.metric("Rho", f"{rho:,.2f}" if pd.notna(rho) else "N/A")
    with col5:
        theta = latest_record['THETA']
        st.metric("Theta", f"{theta:,.2f}" if pd.notna(theta) else "N/A")

    # é£é™©åˆ†æ
    st.markdown("### âš ï¸ é£é™©åˆ†æ")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        if pd.notna(latest_record['DELTA(æœŸæƒ)']) and pd.notna(latest_record['spot price']):
            delta_risk = latest_record['DELTA(æœŸæƒ)'] * latest_record['spot price']
            st.metric("Deltaç°é‡‘é£é™©", f"{delta_risk:,.2f}")
        else:
            st.metric("Deltaç°é‡‘é£é™©", "N/A")
    with col2:
        if pd.notna(latest_record['GAMMA']) and pd.notna(latest_record['spot price']):
            gamma_risk = latest_record['GAMMA'] * (latest_record['spot price'] ** 2) * 0.01
            st.metric("Gammaé£é™©(1%å˜åŠ¨)", f"{gamma_risk:,.2f}")
        else:
            st.metric("Gammaé£é™©(1%å˜åŠ¨)", "N/A")
    with col3:
        if pd.notna(latest_record['VEGA']):
            vega_exposure = latest_record['VEGA'] * 0.01
            st.metric("Vegaé£é™©(1%æ³¢åŠ¨ç‡)", f"{vega_exposure:,.2f}")
        else:
            st.metric("Vegaé£é™©(1%æ³¢åŠ¨ç‡)", "N/A")
    with col4:
        if pd.notna(latest_record['THETA']):
            theta_decay = latest_record['THETA']
            st.metric("æ¯æ—¥ThetaæŸç›Š", f"{theta_decay:,.2f}")
        else:
            st.metric("æ¯æ—¥ThetaæŸç›Š", "N/A")

    # è­¦å‘Šä¿¡æ¯
    if pd.notna(latest_record['åˆ°æœŸæ—¥']):
        days_remaining = (latest_record['åˆ°æœŸæ—¥'] - datetime.datetime.now()).days
        if days_remaining < 30:
            st.warning(f"âš ï¸ è­¦å‘Š: äº¤æ˜“å³å°†åˆ°æœŸ! å‰©ä½™å¤©æ•°: {days_remaining}å¤©")

def min_max_scale(series):
    """Min-Maxæ ‡å‡†åŒ–"""
    positive_count = (series > 0).sum()
    negative_count = (series < 0).sum()

    if positive_count > negative_count:
        return (series - series.min()) / (series.max() - series.min())
    elif negative_count > positive_count:
        return -(series - series.min()) / (series.max() - series.min())
    else:
        return (series - series.min()) / (series.max() - series.min())

def create_greeks_chart(df_normalized):
    """åˆ›å»ºå¸Œè…Šå€¼åˆ†æå›¾è¡¨"""
    x = df_normalized['è§‚å¯Ÿæ—¥']

    fig = go.Figure()

    # æ·»åŠ ç°è´§ä»·æ ¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'spot price' in df_normalized.columns:
        fig.add_trace(go.Scatter(
            x=x, y=df_normalized['spot price'],
            name='Spot Price',
            mode='lines',
            line=dict(color='black', width=2.5),
            marker=dict(size=6, symbol='circle')
        ))

    # æ·»åŠ Deltaï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'DELTA(æœŸæƒ)' in df_normalized.columns:
        fig.add_trace(go.Scatter(
            x=x, y=df_normalized['DELTA(æœŸæƒ)'],
            name='Delta',
            mode='lines',
            line=dict(color='royalblue', width=2, dash='solid'),
            marker=dict(size=6, symbol='circle')
        ))

    # æ·»åŠ Gammaï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'GAMMA' in df_normalized.columns:
        fig.add_trace(go.Scatter(
            x=x, y=df_normalized['GAMMA'],
            name='Gamma',
            mode='lines',
            line=dict(color='firebrick', width=2, dash='dashdot'),
        ))

    # æ·»åŠ Vegaï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'VEGAï¼ˆ1%ï¼‰' in df_normalized.columns:
        fig.add_trace(go.Scatter(
            x=x, y=df_normalized['VEGAï¼ˆ1%ï¼‰'],
            name='Vega',
            mode='lines',
            line=dict(color='green', width=2),
        ))

    # æ·»åŠ Thetaï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'THETA' in df_normalized.columns:
        fig.add_trace(go.Scatter(
            x=x, y=df_normalized['THETA'],
            name='Theta',
            mode='lines',
            line=dict(color='purple', width=2, dash='dot'),
        ))

    # æ·»åŠ Rhoï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'RHO' in df_normalized.columns:
        fig.add_trace(go.Scatter(
            x=x, y=df_normalized['RHO'],
            name='Rho',
            mode='lines',
            line=dict(color='brown', width=2, dash='dash'),
        ))

    # æ·»åŠ æ€»ç›ˆäºï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if 'æ€»ç›ˆäº' in df_normalized.columns:
        fig.add_trace(go.Scatter(
            x=x, y=df_normalized['æ€»ç›ˆäº'],
            name='PNL',
            mode='lines',
            line=dict(color='orange', width=3),
        ))

    fig.update_layout(
        title='Min-Max Standardized Greeks Analysis',
        xaxis_title='Date',
        yaxis_title='Value',
        template='plotly_white',
        hovermode='x unified',
        legend=dict(
            bordercolor='black',
            borderwidth=1
        ),
        hoverlabel=dict(
            bgcolor='white',
            font_size=12,
            font_family='Rockwell'
        ),
        height=500
    )

    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')
    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray', zeroline=True, zerolinecolor='Gray')

    return fig

def create_metric_chart(picked_data, metric_name, title):
    """åˆ›å»ºå•ä¸ªæŒ‡æ ‡çš„é¢ç§¯å›¾"""
    if metric_name not in picked_data.columns:
        return None

    min_y = picked_data[metric_name].min()
    padding = abs(min_y) * 0.1 if min_y != 0 else 0.5
    baseline = min_y - padding

    fig = go.Figure()

    # æ·»åŠ æŠ˜çº¿
    fig.add_trace(go.Scatter(
        x=picked_data['è§‚å¯Ÿæ—¥'],
        y=picked_data[metric_name],
        mode='lines',
        name=metric_name,
        line=dict(color='rgb(0,100,80)', width=2)
    ))

    # æ·»åŠ é˜´å½±åŒºåŸŸ
    fig.add_trace(go.Scatter(
        x=picked_data['è§‚å¯Ÿæ—¥'],
        y=picked_data[metric_name],
        fill='tozeroy',
        mode='none',
        fillcolor='rgba(0,100,80,0.2)',
        showlegend=False
    ))

    fig.update_layout(
        title=title,
        xaxis_title='è§‚å¯Ÿæ—¥',
        yaxis_title=metric_name,
        template='plotly_white',
        yaxis_range=[baseline, picked_data[metric_name].max() + padding],
        height=400
    )

    return fig

# ä¸»åº”ç”¨
def main():
    st.markdown('<div class="main-header">ğŸ“Š äº¤æ˜“ä¿¡æ¯æ±‡æ€»çœ‹æ¿</div>', unsafe_allow_html=True)

    # åŠ è½½æ•°æ®
    try:
        otc_trade = load_data()

        # åº”ç”¨ autoSheetStats.py çš„è®¡ç®—é€»è¾‘
        def compute_delta_cash(row):
            return row['DELTA(æœŸæƒ)'] if pd.isna(row.get("TRADE_KEYWORD.æœŸæƒç‰¹æ®Šç±»å‹")) else row.get('DELTA_CASH', row['DELTA(æœŸæƒ)'])

        def compute_delta(row):
            return row.get('DELTA(TRS)', 0) if pd.isna(row.get("TRADE_KEYWORD.æœŸæƒç‰¹æ®Šç±»å‹")) else row['DELTA(æœŸæƒ)']

        def compute_TRS_notional(row):
            return row['åä¹‰æœ¬é‡‘'] if (pd.isna(row.get("TRADE_KEYWORD.æœŸæƒç‰¹æ®Šç±»å‹")) and row.get('äº¤æ˜“çŠ¶æ€') != 'TERMINATED') else 0

        # è®¡ç®—æ–°åˆ—
        otc_trade['delta cash'] = otc_trade.apply(compute_delta_cash, axis=1)
        otc_trade['delta'] = otc_trade.apply(compute_delta, axis=1)
        otc_trade['spot price'] = otc_trade['delta cash'] / otc_trade['delta'].replace(0, np.nan)
        otc_trade['TRS notional'] = otc_trade.apply(compute_TRS_notional, axis=1)

    except Exception as e:
        st.error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
        st.info("è¯·ç¡®ä¿ 'äº¤æ˜“ä¿¡æ¯æ±‡æ€».xlsx' æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸‹")
        return

    # ä¾§è¾¹æ 
    st.sidebar.header("âš™ï¸ ç­›é€‰é€‰é¡¹")

    # æ—¥æœŸé€‰æ‹©
    st.sidebar.subheader("ğŸ“… æ—¥æœŸé€‰æ‹©")
    available_dates = sorted(otc_trade['è§‚å¯Ÿæ—¥'].unique())

    # å½“å‰æ—¥æœŸï¼ˆé»˜è®¤æœ€æ–°æ—¥æœŸï¼‰
    default_current_idx = len(available_dates) - 1
    current_date = st.sidebar.selectbox(
        "å½“å‰æ—¥æœŸ",
        available_dates,
        index=default_current_idx,
        format_func=lambda x: x.strftime('%Y-%m-%d')
    )

    # å¯¹æ¯”æ—¥æœŸï¼ˆé»˜è®¤å€’æ•°ç¬¬äºŒä¸ªæ—¥æœŸï¼‰
    default_previous_idx = max(0, len(available_dates) - 2)
    previous_date = st.sidebar.selectbox(
        "å¯¹æ¯”æ—¥æœŸ",
        available_dates,
        index=default_previous_idx,
        format_func=lambda x: x.strftime('%Y-%m-%d')
    )

    # äº¤æ˜“IDé€‰æ‹©
    trade_ids = ['å…¨éƒ¨'] + list(otc_trade['Trade Id'].unique())
    selected_trade_id = st.sidebar.selectbox("é€‰æ‹© Trade ID", trade_ids, index=0)

    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ äº¤æ˜“æ¦‚è§ˆ", "ğŸ“… è§‚å¯Ÿæ—¥æ—¥å†", "ğŸ“ˆ å¸Œè…Šå€¼åˆ†æ", "ğŸ“Š æŒ‡æ ‡è¯¦æƒ…"])

    # Tab 1: äº¤æ˜“æ¦‚è§ˆ
    with tab1:
        st.markdown("## äº¤æ˜“æ¦‚è§ˆ")

        # æ˜¾ç¤ºæ±‡æ€»ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»äº¤æ˜“æ•°", len(otc_trade['Trade Id'].unique()))
        with col2:
            total_notional = otc_trade.groupby('Trade Id')['åä¹‰æœ¬é‡‘'].first().sum()
            st.metric("æ€»åä¹‰æœ¬é‡‘", f"{total_notional:,.0f}")
        with col3:
            total_pnl = otc_trade.groupby('Trade Id')['æ€»ç›ˆäº'].last().sum()
            st.metric("æ€»ç›ˆäº", f"{total_pnl:,.2f}")
        with col4:
            avg_vol = otc_trade.groupby('Trade Id')['æ³¢åŠ¨ç‡'].last().mean()
            st.metric("å¹³å‡æ³¢åŠ¨ç‡", f"{avg_vol:.4f}%")

        st.markdown("---")

        # å¦‚æœé€‰æ‹©äº†ç‰¹å®šäº¤æ˜“IDï¼Œæ˜¾ç¤ºè¯¦æƒ…
        if selected_trade_id != 'å…¨éƒ¨':
            print_trade_details(selected_trade_id, otc_trade)
        else:
            st.info("ğŸ“Š æ˜¾ç¤ºæ‰€æœ‰äº¤æ˜“ç»„åˆçš„æ±‡æ€»åˆ†æ")

            # ç»„åˆè´¢åŠ¡æŒ‡æ ‡æ±‡æ€»
            st.markdown("### ğŸ’° ç»„åˆè´¢åŠ¡æŒ‡æ ‡")
            # è·å–æ¯ä¸ªäº¤æ˜“çš„æœ€æ–°æ•°æ®ï¼Œå¹¶ä¿ç•™æœŸæƒç±»å‹å­—æ®µ
            latest_data = otc_trade.groupby('Trade Id').agg({
                'æœŸæƒè´¹': 'last',
                'æœŸæƒä¼°å€¼ NPV': 'last',
                'æ€»ç›ˆäº': 'last',
                'æœ¬å¹´æ€»ç›ˆäº': 'last',
                'éš”å¤œç›ˆäº': 'last',
                'DELTA(æœŸæƒ)': 'last',
                'GAMMA': 'last',
                'VEGA': 'last',
                'THETA': 'last',
                'RHO': 'last',
                'spot price': 'last',
                'åä¹‰æœ¬é‡‘': 'last',
                'TRADE_KEYWORD.æœŸæƒç‰¹æ®Šç±»å‹': 'first'  # ä¿ç•™æœŸæƒç±»å‹
            }).reset_index()

            col1, col2, col3, col4, col5 = st.columns(5)
            with col1:
                total_premium = latest_data['æœŸæƒè´¹'].sum()
                st.metric("æ€»æœŸæƒè´¹", f"{total_premium:,.2f}")
            with col2:
                total_npv = latest_data['æœŸæƒä¼°å€¼ NPV'].sum()
                st.metric("ç»„åˆä¼°å€¼(NPV)", f"{total_npv:,.2f}")
            with col3:
                portfolio_pnl = latest_data['æ€»ç›ˆäº'].sum()
                st.metric("ç»„åˆæ€»ç›ˆäº", f"{portfolio_pnl:,.2f}")
            with col4:
                ytd_pnl = latest_data['æœ¬å¹´æ€»ç›ˆäº'].sum()
                st.metric("æœ¬å¹´æ€»ç›ˆäº", f"{ytd_pnl:,.2f}")
            with col5:
                overnight_pnl = latest_data['éš”å¤œç›ˆäº'].sum()
                st.metric("éš”å¤œç›ˆäº", f"{overnight_pnl:,.2f}")

            st.markdown("---")

            # æŒ‰æ ‡çš„æ±‡æ€»çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆæŒ‰ autoSheetStats.py é€»è¾‘ï¼‰
            st.markdown("### ğŸ“Š æŒ‰æ ‡çš„æ±‡æ€»çš„ç»Ÿè®¡ä¿¡æ¯")

            # è·å–æ¯ä¸ªTrade IDçš„æœ€æ–°è®°å½•
            latest_records = otc_trade.sort_values('è§‚å¯Ÿæ—¥').groupby('Trade Id').last().reset_index()

            # è¿‡æ»¤æœ‰æ•ˆæ ‡çš„ï¼ˆæ ‡çš„åç§°éç©ºï¼‰
            valid_data = latest_records[latest_records['æ ‡çš„åç§°'].notna() & (latest_records['æ ‡çš„åç§°'] != '')].copy()

            # é‡å‘½ååˆ—ä»¥åŒ¹é… autoSheetStats é€»è¾‘
            rename_map = {
                'VEGAï¼ˆ1%ï¼‰': 'vegaï¼ˆ1%ï¼‰',
                'æ³¢åŠ¨ç‡': 'volatilityï¼ˆ%ï¼‰'
            }
            valid_data = valid_data.rename(columns=rename_map)

            # æŒ‰æ ‡çš„åç§°åˆ›å»ºæ•°æ®é€è§†è¡¨
            pivot_summary = valid_data.pivot_table(
                index='æ ‡çš„åç§°',
                values=['delta cash', 'delta', 'vegaï¼ˆ1%ï¼‰', 'spot price', 'volatilityï¼ˆ%ï¼‰', 'TRS notional'],
                aggfunc={
                    'delta cash': 'sum',
                    'delta': 'sum',
                    'vegaï¼ˆ1%ï¼‰': 'sum',
                    'spot price': 'max',
                    'volatilityï¼ˆ%ï¼‰': 'max',
                    'TRS notional': 'sum'
                }
            )

            # æ·»åŠ æ€»å’Œè¡Œ
            total_row = pd.Series({
                'delta cash': pivot_summary['delta cash'].sum(),
                'delta': '',
                'vegaï¼ˆ1%ï¼‰': pivot_summary['vegaï¼ˆ1%ï¼‰'].sum(),
                'spot price': '',
                'volatilityï¼ˆ%ï¼‰': '',
                'TRS notional': pivot_summary['TRS notional'].sum()
            }, name='æ€»å’Œ')
            pivot_summary = pd.concat([pivot_summary, total_row.to_frame().T])

            # é‡æ–°æ’åºåˆ—
            columns_order = ['delta cash', 'delta', 'vegaï¼ˆ1%ï¼‰', 'spot price', 'volatilityï¼ˆ%ï¼‰', 'TRS notional']
            pivot_summary = pivot_summary[columns_order]

            # æ ¼å¼åŒ–æ˜¾ç¤º
            st.dataframe(
                pivot_summary.style.format({
                    'delta cash': lambda x: f'{x:,.2f}' if isinstance(x, (int, float)) else x,
                    'delta': lambda x: f'{x:,.2f}' if isinstance(x, (int, float)) else x,
                    'vegaï¼ˆ1%ï¼‰': lambda x: f'{x:,.2f}' if isinstance(x, (int, float)) else x,
                    'spot price': lambda x: f'{x:,.2f}' if isinstance(x, (int, float)) else x,
                    'volatilityï¼ˆ%ï¼‰': lambda x: f'{x:.4f}' if isinstance(x, (int, float)) else x,
                    'TRS notional': lambda x: f'{x:,.2f}' if isinstance(x, (int, float)) else x
                }),
                use_container_width=True
            )

            st.markdown("---")

            # PNL Explained æŸç›Šæ‹†åˆ†åˆ†æ
            st.markdown("### ğŸ’° PNL Explained æŸç›Šæ‹†åˆ†")

            # è·å–å½“å‰æ—¥æœŸå’Œå¯¹æ¯”æ—¥æœŸçš„æ•°æ®
            current_data = otc_trade[otc_trade['è§‚å¯Ÿæ—¥'] == current_date].copy()
            previous_data = otc_trade[otc_trade['è§‚å¯Ÿæ—¥'] == previous_date].copy()

            if not current_data.empty and not previous_data.empty:
                # è·å–å½“å‰æ—¥æœŸå’Œå¯¹æ¯”æ—¥æœŸçš„æ±‡æ€»ç»Ÿè®¡
                vega_col = 'VEGAï¼ˆ1%ï¼‰' if 'VEGAï¼ˆ1%ï¼‰' in current_data.columns else 'vegaï¼ˆ1%ï¼‰'

                current_summary = current_data.groupby('æ ‡çš„åç§°').agg({
                    'delta cash': 'sum',
                    'delta': 'sum',
                    vega_col: 'sum',
                    'spot price': 'max',
                    'æ³¢åŠ¨ç‡': 'max',
                    'TRS notional': 'sum',
                    'éš”å¤œç›ˆäº': 'sum',
                    'æ€»ç›ˆäº': 'sum'
                }).rename(columns={vega_col: 'vega'})

                previous_summary = previous_data.groupby('æ ‡çš„åç§°').agg({
                    'delta cash': 'sum',
                    'delta': 'sum',
                    vega_col: 'sum',
                    'spot price': 'max',
                    'æ³¢åŠ¨ç‡': 'max',
                    'TRS notional': 'sum'
                }).rename(columns={vega_col: 'vega'})

                # è·å–å½“æ—¥æ–°å¢äº¤æ˜“çš„éš”å¤œç›ˆäº
                new_trades = current_data[pd.to_datetime(current_data['äº¤æ˜“æ—¥æœŸ']).dt.date == current_date.date()]
                new_trade_pnl = new_trades.groupby('æ ‡çš„åç§°')['éš”å¤œç›ˆäº'].sum()

                # è®¡ç®—å¤©æ•°å·®å¼‚
                days_passed = (current_date - previous_date).days

                # æ„å»º PNL Explained è¡¨æ ¼
                pnl_explained_rows = []

                for underlying in current_summary.index:
                    if underlying in previous_summary.index:
                        curr = current_summary.loc[underlying]
                        prev = previous_summary.loc[underlying]

                        # Deltaè§£é‡ŠæŸç›Š = å‰ä¸€æ—¥delta Ã— (å½“æ—¥ä»·æ ¼ - å‰ä¸€æ—¥ä»·æ ¼)
                        delta_pnl = prev['delta'] * (curr['spot price'] - prev['spot price']) if pd.notna(prev['delta']) and pd.notna(curr['spot price']) and pd.notna(prev['spot price']) else 0

                        # Vegaè§£é‡ŠæŸç›Š = å‰ä¸€æ—¥vega Ã— (å½“æ—¥æ³¢åŠ¨ç‡ - å‰ä¸€æ—¥æ³¢åŠ¨ç‡)
                        vega_pnl = prev['vega'] * (curr['æ³¢åŠ¨ç‡'] - prev['æ³¢åŠ¨ç‡']) if pd.notna(prev['vega']) and pd.notna(curr['æ³¢åŠ¨ç‡']) and pd.notna(prev['æ³¢åŠ¨ç‡']) else 0

                        # èµ„é‡‘æˆæœ¬ = -TRSåä¹‰æœ¬é‡‘ Ã— èµ„é‡‘æˆæœ¬ç‡ Ã— å¤©æ•° / 365
                        funding_cost = -prev['TRS notional'] * 0.024 * days_passed / 365 if pd.notna(prev['TRS notional']) else 0

                        # æ–°å¢äº¤æ˜“æŸç›Š
                        new_trade_gain = new_trade_pnl.get(underlying, 0)

                        # è§£é‡ŠæŸç›Š = Deltaè§£é‡Š + Vegaè§£é‡Š + èµ„é‡‘æˆæœ¬ + æ–°å¢äº¤æ˜“æŸç›Š
                        explained_pnl = delta_pnl + vega_pnl + funding_cost + new_trade_gain

                        # éš”å¤œç›ˆäº
                        overnight_pnl = curr['éš”å¤œç›ˆäº']

                        # æœªè§£é‡ŠæŸç›Š = éš”å¤œç›ˆäº - è§£é‡ŠæŸç›Š
                        unexplained_pnl = overnight_pnl - explained_pnl

                        # æ ‡çš„ä»·æ ¼æ¶¨è·Œå¹…åº¦
                        price_change_pct = (curr['spot price'] / prev['spot price'] - 1) if pd.notna(curr['spot price']) and pd.notna(prev['spot price']) and prev['spot price'] != 0 else 0

                        # æ³¢åŠ¨ç‡å˜åŠ¨ç»å¯¹å€¼
                        vol_change = curr['æ³¢åŠ¨ç‡'] - prev['æ³¢åŠ¨ç‡'] if pd.notna(curr['æ³¢åŠ¨ç‡']) and pd.notna(prev['æ³¢åŠ¨ç‡']) else 0

                        pnl_explained_rows.append({
                            'æ ‡çš„': underlying,
                            'Deltaè§£é‡ŠæŸç›Š': delta_pnl,
                            'Vegaè§£é‡ŠæŸç›Š': vega_pnl,
                            'èµ„é‡‘æˆæœ¬': funding_cost,
                            'æ–°å¢äº¤æ˜“æŸç›Š': new_trade_gain,
                            'è§£é‡ŠæŸç›Š': explained_pnl,
                            'éš”å¤œç›ˆäº': overnight_pnl,
                            'æœªè§£é‡ŠæŸç›Š': unexplained_pnl,
                            'æ€»ç›ˆäº': curr['æ€»ç›ˆäº'],
                            'æ ‡çš„ä»·æ ¼æ¶¨è·Œ': f"{price_change_pct:.2%}",
                            'æ³¢åŠ¨ç‡å˜åŠ¨': f"{vol_change:.4f}"
                        })

                if pnl_explained_rows:
                    pnl_df = pd.DataFrame(pnl_explained_rows)

                    # æ·»åŠ æ€»å’Œè¡Œ
                    total_row = {
                        'æ ‡çš„': 'æ€»å’Œ',
                        'Deltaè§£é‡ŠæŸç›Š': pnl_df['Deltaè§£é‡ŠæŸç›Š'].sum(),
                        'Vegaè§£é‡ŠæŸç›Š': pnl_df['Vegaè§£é‡ŠæŸç›Š'].sum(),
                        'èµ„é‡‘æˆæœ¬': pnl_df['èµ„é‡‘æˆæœ¬'].sum(),
                        'æ–°å¢äº¤æ˜“æŸç›Š': pnl_df['æ–°å¢äº¤æ˜“æŸç›Š'].sum(),
                        'è§£é‡ŠæŸç›Š': pnl_df['è§£é‡ŠæŸç›Š'].sum(),
                        'éš”å¤œç›ˆäº': pnl_df['éš”å¤œç›ˆäº'].sum(),
                        'æœªè§£é‡ŠæŸç›Š': pnl_df['æœªè§£é‡ŠæŸç›Š'].sum(),
                        'æ€»ç›ˆäº': pnl_df['æ€»ç›ˆäº'].sum(),
                        'æ ‡çš„ä»·æ ¼æ¶¨è·Œ': '',
                        'æ³¢åŠ¨ç‡å˜åŠ¨': ''
                    }
                    pnl_df = pd.concat([pnl_df, pd.DataFrame([total_row])], ignore_index=True)

                    # æ˜¾ç¤ºæ—¥æœŸä¿¡æ¯
                    st.info(f"ğŸ“… å¯¹æ¯”åˆ†æï¼š{previous_date.strftime('%Y-%m-%d')} â†’ {current_date.strftime('%Y-%m-%d')} ({days_passed}å¤©)")

                    # æ ¼å¼åŒ–æ˜¾ç¤º
                    st.dataframe(
                        pnl_df.style.format({
                            'Deltaè§£é‡ŠæŸç›Š': '{:,.2f}',
                            'Vegaè§£é‡ŠæŸç›Š': '{:,.2f}',
                            'èµ„é‡‘æˆæœ¬': '{:,.2f}',
                            'æ–°å¢äº¤æ˜“æŸç›Š': '{:,.2f}',
                            'è§£é‡ŠæŸç›Š': '{:,.2f}',
                            'éš”å¤œç›ˆäº': '{:,.2f}',
                            'æœªè§£é‡ŠæŸç›Š': '{:,.2f}',
                            'æ€»ç›ˆäº': '{:,.2f}'
                        }).apply(lambda x: ['background-color: #f0f2f6' if x.name == len(pnl_df) - 1 else '' for _ in x], axis=1),
                        use_container_width=True
                    )

                    # å…³é”®æŒ‡æ ‡å¡ç‰‡
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        total_explained = pnl_df[pnl_df['æ ‡çš„'] == 'æ€»å’Œ']['è§£é‡ŠæŸç›Š'].iloc[0]
                        st.metric("æ€»è§£é‡ŠæŸç›Š", f"{total_explained:,.2f}")
                    with col2:
                        total_overnight = pnl_df[pnl_df['æ ‡çš„'] == 'æ€»å’Œ']['éš”å¤œç›ˆäº'].iloc[0]
                        st.metric("æ€»éš”å¤œç›ˆäº", f"{total_overnight:,.2f}")
                    with col3:
                        total_unexplained = pnl_df[pnl_df['æ ‡çš„'] == 'æ€»å’Œ']['æœªè§£é‡ŠæŸç›Š'].iloc[0]
                        st.metric("æ€»æœªè§£é‡ŠæŸç›Š", f"{total_unexplained:,.2f}")
                    with col4:
                        explanation_rate = (total_explained / total_overnight * 100) if total_overnight != 0 else 0
                        st.metric("è§£é‡Šç‡", f"{explanation_rate:.1f}%")

                else:
                    st.warning("âš ï¸ æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡ŒæŸç›Šæ‹†åˆ†åˆ†æ")
            else:
                st.warning("âš ï¸ æ‰€é€‰æ—¥æœŸæ²¡æœ‰å¯ç”¨æ•°æ®")

            st.markdown("---")

            # æ˜¾ç¤ºæ‰€æœ‰äº¤æ˜“æ±‡æ€»è¡¨
            st.markdown("### ğŸ“‹ æ‰€æœ‰äº¤æ˜“æ±‡æ€»")
            summary_df = otc_trade.groupby('Trade Id').agg({
                'æ ‡çš„åç§°': 'first',
                'TRADE_KEYWORD.æœŸæƒç‰¹æ®Šç±»å‹': 'first',
                'äº¤æ˜“æ—¥æœŸ': 'first',
                'åˆ°æœŸæ—¥': 'first',
                'åä¹‰æœ¬é‡‘': 'first',
                'æ€»ç›ˆäº': 'last',
                'æœŸæƒä¼°å€¼ NPV': 'last',
                'DELTA(æœŸæƒ)': 'last',
                'GAMMA': 'last',
                'VEGA': 'last'
            }).reset_index()

            # æ ¼å¼åŒ–æ˜¾ç¤º
            summary_df.columns = ['Trade ID', 'æ ‡çš„', 'æœŸæƒç±»å‹', 'äº¤æ˜“æ—¥æœŸ', 'åˆ°æœŸæ—¥',
                                  'åä¹‰æœ¬é‡‘', 'æ€»ç›ˆäº', 'NPV', 'Delta', 'Gamma', 'Vega']
            st.dataframe(summary_df, use_container_width=True)

    # Tab 2: è§‚å¯Ÿæ—¥æ—¥å†
    with tab2:
        st.markdown("## é›ªçƒæ•²å‡ºè§‚å¯Ÿæ—¥æ—¥å†")

        try:
            obs_df = expand_observation_dates(otc_trade)

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ç‹¬ç«‹é›ªçƒæœŸæƒäº¤æ˜“", len(obs_df['Trade Id'].unique()))
            with col2:
                st.metric("æ€»è§‚å¯Ÿæ—¥è®°å½•", len(obs_df))
            with col3:
                date_range = f"{obs_df['è§‚å¯Ÿæ—¥'].min().strftime('%Y-%m-%d')} è‡³ {obs_df['è§‚å¯Ÿæ—¥'].max().strftime('%Y-%m-%d')}"
                st.info(f"æ—¥æœŸèŒƒå›´: {date_range}")

            # æ˜¾ç¤ºæ—¥å†çƒ­åŠ›å›¾
            calendar_fig = create_enhanced_calendar_heatmap(obs_df)
            st.plotly_chart(calendar_fig, use_container_width=True)

        except Exception as e:
            st.error(f"æ—¥å†ç”Ÿæˆå¤±è´¥: {e}")

    # Tab 3: å¸Œè…Šå€¼åˆ†æ
    with tab3:
        st.markdown("## å¸Œè…Šå€¼åˆ†æ")

        # å‡†å¤‡æ•°æ®
        if selected_trade_id == 'å…¨éƒ¨':
            st.info("ğŸ“Œ æç¤ºï¼šDeltaå’ŒGammaä¸èƒ½è·¨æ ‡çš„åŠ æ€»ï¼Œå·²æŒ‰èµ„äº§ç±»åˆ«åˆ†åˆ«å±•ç¤º")

            # è·å–æ‰€æœ‰æ ‡çš„åˆ—è¡¨
            underlying_list = sorted(otc_trade['æ ‡çš„åç§°'].unique().tolist())

            # æ·»åŠ å¯è§†åŒ–æ¨¡å¼é€‰æ‹©
            viz_mode = st.radio(
                "é€‰æ‹©å¯è§†åŒ–æ¨¡å¼",
                ["åˆ†èµ„äº§å¯¹æ¯”å›¾", "å•ä¸€èµ„äº§è¯¦æƒ…", "ç»„åˆçº§æŒ‡æ ‡(ä»…Vega/Theta)"],
                horizontal=True
            )

            if viz_mode == "ç»„åˆçº§æŒ‡æ ‡(ä»…Vega/Theta)":
                # ä»…æ˜¾ç¤ºå¯è·¨æ ‡çš„åŠ æ€»çš„æŒ‡æ ‡ï¼šVegaã€Thetaã€Rho
                #verified_data = otc_trade[otc_trade['äº¤æ˜“çŠ¶æ€']=='VERIFIED'].copy()
                verified_data = otc_trade.copy()

                # æŒ‰è§‚å¯Ÿæ—¥ç›´æ¥æ±‡æ€»
                time_series_data = verified_data.groupby('è§‚å¯Ÿæ—¥').agg({
                    'æœŸæƒä¼°å€¼ï¼ˆæŠ¥é€ï¼‰': 'sum',
                    'æœŸæƒä¼°å€¼ NPV': 'sum',
                    'æœŸæƒè´¹ä¼°å€¼': 'sum',
                    'VEGAï¼ˆ1%ï¼‰': 'sum',
                    'THETA': 'sum',
                    'RHO': 'sum',
                    'æ€»ç›ˆäº': 'sum'
                }).reset_index()

                picked_data = time_series_data.set_index('è§‚å¯Ÿæ—¥')
                cols_to_normalize = ['æœŸæƒä¼°å€¼ï¼ˆæŠ¥é€ï¼‰','æœŸæƒä¼°å€¼ NPV','æœŸæƒè´¹ä¼°å€¼','VEGAï¼ˆ1%ï¼‰','THETA','RHO','æ€»ç›ˆäº']

                # æ ‡å‡†åŒ–
                df_normalized = picked_data.copy()
                df_normalized[cols_to_normalize] = df_normalized[cols_to_normalize].apply(min_max_scale)
                df_normalized = round(df_normalized, 4)
                df_normalized.reset_index(inplace=True)

                # æ˜¾ç¤ºå¸Œè…Šå€¼ç»¼åˆå›¾è¡¨
                greeks_fig = create_greeks_chart(df_normalized)
                st.plotly_chart(greeks_fig, use_container_width=True)

            elif viz_mode == "å•ä¸€èµ„äº§è¯¦æƒ…":
                # é€‰æ‹©å•ä¸€æ ‡çš„æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
                selected_underlying = st.selectbox("é€‰æ‹©æ ‡çš„èµ„äº§", underlying_list, index=0)

                # æŒ‰é€‰å®šæ ‡çš„ç­›é€‰æ•°æ®
                underlying_data = otc_trade[
                    otc_trade['æ ‡çš„åç§°'] == selected_underlying
                ].copy()

                # æŒ‰è§‚å¯Ÿæ—¥ç›´æ¥æ±‡æ€»è¯¥æ ‡çš„çš„æ‰€æœ‰è®°å½•
                time_series_data = underlying_data.groupby('è§‚å¯Ÿæ—¥').agg({
                    'spot price': 'first',  # spot priceå¯¹åŒä¸€æ ‡çš„åŒä¸€å¤©åº”è¯¥æ˜¯ç›¸åŒçš„
                    'æœŸæƒä¼°å€¼ï¼ˆæŠ¥é€ï¼‰': 'sum',
                    'æœŸæƒä¼°å€¼ NPV': 'sum',
                    'æœŸæƒè´¹ä¼°å€¼': 'sum',
                    'DELTA(æœŸæƒ)': 'sum',
                    'GAMMA': 'sum',
                    'VEGAï¼ˆ1%ï¼‰': 'sum',
                    'THETA': 'sum',
                    'RHO': 'sum',
                    'æ€»ç›ˆäº': 'sum'
                }).reset_index()

                picked_data = time_series_data.set_index('è§‚å¯Ÿæ—¥')
                cols_to_normalize = ['spot price','æœŸæƒä¼°å€¼ï¼ˆæŠ¥é€ï¼‰','æœŸæƒä¼°å€¼ NPV','æœŸæƒè´¹ä¼°å€¼','DELTA(æœŸæƒ)','GAMMA','VEGAï¼ˆ1%ï¼‰','THETA','RHO','æ€»ç›ˆäº']

                # æ ‡å‡†åŒ–
                df_normalized = picked_data.copy()
                df_normalized[cols_to_normalize] = df_normalized[cols_to_normalize].apply(min_max_scale)
                df_normalized = round(df_normalized, 4)
                df_normalized.reset_index(inplace=True)

                # æ˜¾ç¤ºå¸Œè…Šå€¼ç»¼åˆå›¾è¡¨
                greeks_fig = create_greeks_chart(df_normalized)
                st.plotly_chart(greeks_fig, use_container_width=True)

            else:  # åˆ†èµ„äº§å¯¹æ¯”å›¾æ¨¡å¼
                # å‡†å¤‡æŒ‰æ ‡çš„åˆ†ç»„çš„æ•°æ®
                #verified_data = otc_trade[otc_trade['äº¤æ˜“çŠ¶æ€']=='VERIFIED'].copy()
                verified_data = otc_trade.copy()

                # æŒ‰è§‚å¯Ÿæ—¥å’Œæ ‡çš„åç§°ç›´æ¥æ±‡æ€»
                underlying_summary = verified_data.groupby(['è§‚å¯Ÿæ—¥', 'æ ‡çš„åç§°']).agg({
                    'spot price': 'first',
                    'DELTA(æœŸæƒ)': 'sum',
                    'GAMMA': 'sum',
                    'VEGAï¼ˆ1%ï¼‰': 'sum',
                    'THETA': 'sum',
                    'æ€»ç›ˆäº': 'sum',
                    'éš”å¤œç›ˆäº': 'sum'
                }).reset_index()

                # é€‰æ‹©è¦å±•ç¤ºçš„å¸Œè…Šå€¼
                greek_to_plot = st.selectbox(
                    "é€‰æ‹©å¸Œè…Šå€¼æŒ‡æ ‡",
                    ['DELTA(æœŸæƒ)', 'GAMMA', 'VEGAï¼ˆ1%ï¼‰', 'THETA', 'æ€»ç›ˆäº', 'éš”å¤œç›ˆäº'],
                    index=0
                )

                # æ·»åŠ è¯´æ˜
                if greek_to_plot == 'æ€»ç›ˆäº':
                    st.info("ğŸ’¡ æ€»ç›ˆäºæ˜¯ç´¯ç§¯å€¼ï¼Œæ˜¾ç¤ºä»äº¤æ˜“å¼€å§‹è‡³è¯¥æ—¥çš„ç´¯è®¡ç›ˆäº")
                elif greek_to_plot == 'éš”å¤œç›ˆäº':
                    st.info("ğŸ’¡ éš”å¤œç›ˆäºæ˜¯å•æ—¥å¢é‡å€¼ï¼Œæ˜¾ç¤ºè¯¥æ—¥çš„ç›ˆäºå˜åŒ–")

                # åˆ›å»ºåˆ†èµ„äº§å¯¹æ¯”å›¾
                fig = go.Figure()

                colors = ['royalblue', 'firebrick', 'green', 'purple', 'orange', 'brown', 'pink', 'cyan']

                for idx, underlying in enumerate(underlying_list):
                    underlying_df = underlying_summary[underlying_summary['æ ‡çš„åç§°'] == underlying]

                    if not underlying_df.empty:
                        fig.add_trace(go.Scatter(
                            x=underlying_df['è§‚å¯Ÿæ—¥'],
                            y=underlying_df[greek_to_plot],
                            name=underlying,
                            mode='lines+markers',
                            line=dict(color=colors[idx % len(colors)], width=2),
                            marker=dict(size=5)
                        ))

                fig.update_layout(
                    title=f'{greek_to_plot} - æŒ‰æ ‡çš„èµ„äº§å¯¹æ¯”',
                    xaxis_title='è§‚å¯Ÿæ—¥',
                    yaxis_title=greek_to_plot,
                    template='plotly_white',
                    hovermode='x unified',
                    legend=dict(
                        bordercolor='black',
                        borderwidth=1
                    ),
                    height=600
                )

                fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')
                fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray', zeroline=True, zerolinecolor='Gray')

                st.plotly_chart(fig, use_container_width=True)

                # æ·»åŠ åˆ†é¢å›¾ï¼ˆæ¯ä¸ªæ ‡çš„ä¸€ä¸ªå­å›¾ï¼‰
                st.markdown("---")
                st.markdown("### ğŸ“Š åˆ†æ ‡çš„è¯¦ç»†è§†å›¾")

                n_underlyings = len(underlying_list)
                rows = int(np.ceil(n_underlyings / 2))

                fig_facet = make_subplots(
                    rows=rows, cols=2,
                    subplot_titles=[f"<b>{ul}</b>" for ul in underlying_list],
                    vertical_spacing=0.12,
                    horizontal_spacing=0.1
                )

                for idx, underlying in enumerate(underlying_list):
                    row = idx // 2 + 1
                    col = idx % 2 + 1

                    underlying_df = underlying_summary[underlying_summary['æ ‡çš„åç§°'] == underlying]

                    if not underlying_df.empty:
                        fig_facet.add_trace(
                            go.Scatter(
                                x=underlying_df['è§‚å¯Ÿæ—¥'],
                                y=underlying_df[greek_to_plot],
                                name=underlying,
                                mode='lines+markers',
                                line=dict(color=colors[idx % len(colors)], width=2),
                                marker=dict(size=4),
                                showlegend=False
                            ),
                            row=row, col=col
                        )

                fig_facet.update_layout(
                    title=f'{greek_to_plot} - åˆ†æ ‡çš„å±•ç¤º',
                    height=300 * rows,
                    template='plotly_white'
                )

                fig_facet.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')
                fig_facet.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray', zeroline=True, zerolinecolor='Gray')

                st.plotly_chart(fig_facet, use_container_width=True)

        else:
            picked_data = otc_trade.loc[otc_trade['Trade Id'] == selected_trade_id]
            picked_data = picked_data[['è§‚å¯Ÿæ—¥','spot price','æœŸæƒä¼°å€¼ï¼ˆæŠ¥é€ï¼‰','æœŸæƒä¼°å€¼ NPV','æœŸæƒè´¹ä¼°å€¼','DELTA(æœŸæƒ)','GAMMA','VEGAï¼ˆ1%ï¼‰','THETA','RHO','æ€»ç›ˆäº','äº¤æ˜“çŠ¶æ€']]
            #picked_data = picked_data.loc[picked_data['äº¤æ˜“çŠ¶æ€']=='VERIFIED']
            cols_to_normalize = ['spot price','æœŸæƒä¼°å€¼ï¼ˆæŠ¥é€ï¼‰','æœŸæƒä¼°å€¼ NPV','æœŸæƒè´¹ä¼°å€¼','DELTA(æœŸæƒ)','GAMMA','VEGAï¼ˆ1%ï¼‰','THETA','RHO','æ€»ç›ˆäº']

            # æ ‡å‡†åŒ–
            df_normalized = picked_data.copy()
            df_normalized[cols_to_normalize] = df_normalized[cols_to_normalize].apply(min_max_scale)
            df_normalized = round(df_normalized, 4)
            df_normalized.reset_index(inplace=True)

            # æ˜¾ç¤ºå¸Œè…Šå€¼ç»¼åˆå›¾è¡¨
            greeks_fig = create_greeks_chart(df_normalized)
            st.plotly_chart(greeks_fig, use_container_width=True)

    # Tab 4: æŒ‡æ ‡è¯¦æƒ…
    with tab4:
        st.markdown("## æŒ‡æ ‡è¯¦æƒ…")

        if selected_trade_id == 'å…¨éƒ¨':
            st.warning("è¯·é€‰æ‹©ç‰¹å®šçš„ Trade ID æŸ¥çœ‹æŒ‡æ ‡è¯¦æƒ…")
        else:
            picked_data = otc_trade.loc[otc_trade['Trade Id'] == selected_trade_id]
            picked_data = picked_data.loc[picked_data['äº¤æ˜“çŠ¶æ€']=='VERIFIED']

            # åˆ›å»ºå„ä¸ªæŒ‡æ ‡å›¾è¡¨
            metrics = [
                ('spot price', 'Spot Price'),
                ('DELTA(æœŸæƒ)', 'DELTA(æœŸæƒ)'),
                ('GAMMA', 'GAMMA'),
                ('VEGAï¼ˆ1%ï¼‰', 'VEGAï¼ˆ1%ï¼‰')
            ]

            for metric_name, title in metrics:
                fig = create_metric_chart(picked_data, metric_name, title)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)

if __name__ == "__main__":
    main()
